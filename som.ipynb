{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOM (Self-Organizing Map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from som import SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Self Organizing Map')\n",
    "parser.add_argument('--color', dest='dataset', action='store_const',\n",
    "                    const='color', default=None,\n",
    "                    help='use color')\n",
    "parser.add_argument('--mnist', dest='dataset', action='store_const',\n",
    "                    const='mnist', default=None,\n",
    "                    help='use mnist dataset')\n",
    "parser.add_argument('--fashion_mnist', dest='dataset', action='store_const',\n",
    "                    const='fashion_mnist', default=None,\n",
    "                    help='use mnist dataset')\n",
    "parser.add_argument('--train', action='store_const',\n",
    "                    const=True, default=False,\n",
    "                    help='train network')\n",
    "parser.add_argument('--dataset', type=str, default='mnist', help='dataset name')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='input batch size')\n",
    "parser.add_argument('--lr', type=float, default=0.3, help='input learning rate')\n",
    "parser.add_argument('--epoch', type=int, default=100, help='input total epoch')\n",
    "parser.add_argument('--data_dir', type=str, default='./datasets', help='set a data directory')\n",
    "parser.add_argument('--res_dir', type=str, default='./results', help='set a result directory')\n",
    "parser.add_argument('--model_dir', type=str, default='./model', help='set a model directory')\n",
    "parser.add_argument('--row', type=int, default=20, help='set SOM row length')\n",
    "parser.add_argument('--col', type=int, default=20, help='set SOM col length')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "class SOM(nn.Module):\n",
    "    def __init__(self, input_size, out_size=(10, 10), lr=0.3, sigma=None):\n",
    "        '''\n",
    "        parameter들의 input size, output size, learning rate, sigma 이용\n",
    "        \n",
    "        '''\n",
    "        super(SOM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        self.lr = lr\n",
    "        if sigma is None:\n",
    "            self.sigma = max(out_size) / 2\n",
    "        else:\n",
    "            self.sigma = float(sigma)\n",
    "\n",
    "        self.weight = nn.Parameter(torch.randn(input_size, out_size[0] * out_size[1]), requires_grad=False)\n",
    "        self.locations = nn.Parameter(torch.Tensor(list(self.get_map_index())), requires_grad=False)\n",
    "        self.pdist_fn = nn.PairwiseDistance(p=2)\n",
    "\n",
    "    def get_map_index(self):\n",
    "        '''\n",
    "        2차원 매핑 함수의 이용\n",
    "        '''\n",
    "        for x in range(self.out_size[0]):\n",
    "            for y in range(self.out_size[1]):\n",
    "                yield (x, y)\n",
    "\n",
    "    def _neighborhood_fn(self, input, current_sigma):\n",
    "        '''\n",
    "        e^(-(input / sigma^2))\n",
    "        '''\n",
    "        input.div_(current_sigma ** 2)\n",
    "        input.neg_()\n",
    "        input.exp_()\n",
    "\n",
    "        return input\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        best matching unit(bmu) 위치 탐색\n",
    "        : parameter 입력값 : 데이터로 지정\n",
    "        :return: location of best matching unit, loss\n",
    "        '''\n",
    "        batch_size = input.size()[0]\n",
    "        input = input.view(batch_size, -1, 1)\n",
    "        batch_weight = self.weight.expand(batch_size, -1, -1)\n",
    "\n",
    "        dists = self.pdist_fn(input, batch_weight)\n",
    "        # bmu 탐색\n",
    "        losses, bmu_indexes = dists.min(dim=1, keepdim=True)\n",
    "        bmu_locations = self.locations[bmu_indexes]\n",
    "\n",
    "        return bmu_locations, losses.sum().div_(batch_size).item()\n",
    "\n",
    "    def self_organizing(self, input, current_iter, max_iter):\n",
    "        '''\n",
    "        Self Oranizing Map(SOM)을 이용하여 학습 진행\n",
    "        :param input: 학습 데이터\n",
    "        :param current_iter: 전체 epoch 중 현재 epoch\n",
    "        :param max_iter: 전체 epoch\n",
    "        :return: loss (최소 거리 반환)\n",
    "        '''\n",
    "        batch_size = input.size()[0]\n",
    "        # learning rate 설정\n",
    "        iter_correction = 1.0 - current_iter / max_iter\n",
    "        lr = self.lr * iter_correction\n",
    "        sigma = self.sigma * iter_correction\n",
    "\n",
    "        # best matching unit 탐색\n",
    "        bmu_locations, loss = self.forward(input)\n",
    "\n",
    "        # 마할라노비스 거리에 기반하여 계산\n",
    "        distance_squares = self.locations.float() - bmu_locations.float()\n",
    "        distance_squares.pow_(2)\n",
    "        distance_squares = torch.sum(distance_squares, dim=2)\n",
    "        \n",
    "        # learning rate에 기반하여 각 노드의 위치 계산\n",
    "        lr_locations = self._neighborhood_fn(distance_squares, sigma)\n",
    "        lr_locations.mul_(lr).unsqueeze_(1)\n",
    "\n",
    "        # 델타 계산\n",
    "        delta = lr_locations * (input.unsqueeze(2) - self.weight)\n",
    "        delta = delta.sum(dim=0)\n",
    "        delta.div_(batch_size)\n",
    "        self.weight.data.add_(delta)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def save_result(self, dir, im_size=(0, 0, 0)):\n",
    "        \n",
    "        '''\n",
    "        Self Organizing Map(SOM)의 결과 시각화\n",
    "        : parameter directory : 저장할 경로 지정\n",
    "        : image size : 채널, x,y 크기 지정\n",
    "        :return:\n",
    "        \n",
    "        '''\n",
    "        # 이미지의 weight 구하기\n",
    "        images = self.weight.view(im_size[0], im_size[1], im_size[2], self.out_size[0] * self.out_size[1])\n",
    "\n",
    "        images = images.permute(3, 0, 1, 2)\n",
    "        save_image(images, dir, normalize=True, padding=1, nrow=self.out_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=32, col=20, data_dir='./datasets', dataset=None, epoch=100, lr=0.3, model_dir='./model', res_dir='./results', row=20, train=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = args.dataset\n",
    "batch_size = args.batch_size\n",
    "total_epoch = args.epoch\n",
    "row = args.row\n",
    "col = args.col\n",
    "train = args.train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Dataset : MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'mnist'\n",
    "# Hyper-parameters\n",
    "DATA_DIR = args.data_dir + '/' + args.dataset\n",
    "RES_DIR = args.res_dir + '/' + args.dataset\n",
    "MODEL_DIR = args.model_dir + '/' + args.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dir\n",
    "if not os.path.exists(args.res_dir):\n",
    "    os.makedirs(args.res_dir)\n",
    "\n",
    "# Create results/datasetname dir\n",
    "if not os.path.exists(RES_DIR):\n",
    "    os.makedirs(RES_DIR)\n",
    "\n",
    "# Create model dir\n",
    "if not os.path.exists(args.model_dir):\n",
    "    os.makedirs(args.model_dir)\n",
    "\n",
    "# Create model/datasetname dir\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = datasets.MNIST(DATA_DIR, train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model...\n",
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "# train_data.train_data = train_data.train_data[:5000]\n",
    "# train_data.train_labels = train_data.train_labels[:5000]\n",
    "\n",
    "print('Building Model...')\n",
    "som = SOM(input_size=28 * 28 * 1, out_size=(row, col))\n",
    "if os.path.exists('%s/som.pth' % MODEL_DIR):\n",
    "    som.load_state_dict(torch.load('%s/som.pth' % MODEL_DIR))\n",
    "    print('Model Loaded!')\n",
    "else:\n",
    "    print('Create Model!')\n",
    "som = som.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train == True:\n",
    "    losses = list()\n",
    "    for epoch in range(total_epoch):\n",
    "        running_loss = 0\n",
    "        start_time = time.time()\n",
    "        for idx, (X, Y) in enumerate(train_loader):\n",
    "            X = X.view(-1, 28 * 28 * 1).to(device)    # flatten\n",
    "            loss = som.self_organizing(X, epoch, total_epoch)    # train som\n",
    "            running_loss += loss\n",
    "\n",
    "        losses.append(running_loss)\n",
    "        print('epoch = %d, loss = %.2f, time = %.2fs' % (epoch + 1, running_loss, time.time() - start_time))\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            # model save\n",
    "            som.save_result('%s/som_epoch_%d.png' % (RES_DIR, epoch), (1, 28, 28))\n",
    "            torch.save(som.state_dict(), '%s/som.pth' % MODEL_DIR)\n",
    "\n",
    "    torch.save(som.state_dict(), '%s/som.pth' % MODEL_DIR)\n",
    "    plt.title('SOM loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "\n",
    "som.save_result('%s/som_result.png' % (RES_DIR), (1, 28, 28))\n",
    "torch.save(som.state_dict(), '%s/som.pth' % MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./results/mnist/som_animation.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='./results/mnist/som_animation.gif')  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Dataset : Fashion_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'fashion_mnist'\n",
    "# Hyper-parameters\n",
    "DATA_DIR = args.data_dir + '/' + args.dataset\n",
    "RES_DIR = args.res_dir + '/' + args.dataset\n",
    "MODEL_DIR = args.model_dir + '/' + args.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = datasets.FashionMNIST(DATA_DIR, train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model...\n",
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "# from som import SOM\n",
    "\n",
    "# train data:5000까지 cutting 진행\n",
    "# model load\n",
    "\n",
    "# train_data.train_data = train_data.train_data[:5000]\n",
    "# train_data.train_labels = train_data.train_labels[:5000]\n",
    "\n",
    "print('Building Model...')\n",
    "som = SOM(input_size=28 * 28 * 1, out_size=(row, col))\n",
    "if os.path.exists('%s/som.pth' % MODEL_DIR):\n",
    "    som.load_state_dict(torch.load('%s/som.pth' % MODEL_DIR))\n",
    "    print('Model Loaded!')\n",
    "else:\n",
    "    print('Create Model!')\n",
    "som = som.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train == True:\n",
    "    losses = list()\n",
    "    for epoch in range(total_epoch):\n",
    "        running_loss = 0\n",
    "        start_time = time.time()\n",
    "        for idx, (X, Y) in enumerate(train_loader):\n",
    "            X = X.view(-1, 28 * 28 * 1).to(device)    # flatten\n",
    "            loss = som.self_organizing(X, epoch, total_epoch)    # train som\n",
    "            running_loss += loss\n",
    "\n",
    "        losses.append(running_loss)\n",
    "        print('epoch = %d, loss = %.2f, time = %.2fs' % (epoch + 1, running_loss, time.time() - start_time))\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            # model save\n",
    "            som.save_result('%s/som_epoch_%d.png' % (RES_DIR, epoch), (1, 28, 28))\n",
    "            torch.save(som.state_dict(), '%s/som.pth' % MODEL_DIR)\n",
    "\n",
    "    torch.save(som.state_dict(), '%s/som.pth' % MODEL_DIR)\n",
    "    plt.title('SOM loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "\n",
    "som.save_result('%s/som_result.png' % (RES_DIR), (1, 28, 28))\n",
    "torch.save(som.state_dict(), '%s/som.pth' % MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./results/fashion_mnist/som_animation.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='./results/fashion_mnist/som_animation.gif')  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reference List\n",
    "- https://ratsgo.github.io/machine%20learning/2017/05/01/SOM/\n",
    "- https://github.com/FlorisHoogenboom/som-anomaly-detector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
